{"cells":[{"cell_type":"code","execution_count":null,"id":"05128230","metadata":{"id":"05128230"},"outputs":[],"source":["# Mounting Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"id":"35ffd9b8","metadata":{"id":"35ffd9b8"},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from itertools import chain\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.datasets import ImageFolder\n"]},{"cell_type":"code","execution_count":null,"id":"d7f9acd7","metadata":{"id":"d7f9acd7"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/IS675_data/DL Project/age_gender.csv')\n","\n","# Check the structure and data types\n","print(df.info())\n","# View the first few rows\n","print(df.head())\n","\n","# 1. Check for missing values\n","missing_values = df.isnull().sum()\n","print(\"Missing Values:\\n\", missing_values[missing_values > 0])\n","\n","# 2. Check for duplicate rows\n","duplicates = df.duplicated().sum()\n","print(f\"Number of duplicate rows: {duplicates}\")\n","\n","# 3. Check for data types and inconsistent data types\n","data_types = df.dtypes\n","print(\"Data Types:\\n\", data_types)\n"]},{"cell_type":"code","execution_count":null,"id":"43d5ca22","metadata":{"id":"43d5ca22"},"outputs":[],"source":["def clean_pixels(df):\n","    # Check if the 'pixels' column is of type string (only convert if it is)\n","    if df['pixels'].dtype == 'object':  # Check data type of the column\n","        # Convert pixels string to list of integers\n","        df['pixels'] = df['pixels'].apply(lambda x: list(map(int, x.split())))\n","    return df\n","\n","df = pd.read_csv('/content/drive/MyDrive/IS675_data/DL Project/age_gender.csv')\n","\n","# Apply the cleaning function (only once)\n","df_cleaned = clean_pixels(df)\n","\n","# Display the first few rows of the cleaned dataframe\n","print(\"Sample of cleaned data:\")\n","print(df_cleaned.head())\n","\n","# Check for any missing values\n","print(\"\\\n","Missing values:\")\n","print(df_cleaned.isnull().sum())\n"]},{"cell_type":"code","execution_count":null,"id":"50f1e284","metadata":{"id":"50f1e284"},"outputs":[],"source":["# Check the number of records (rows) and variables (columns)\n","num_records, num_variables = df.shape\n","print(f\"Number of records (rows): {num_records}\")\n","print(f\"Number of variables (columns): {num_variables}\")\n"]},{"cell_type":"code","execution_count":null,"id":"a7063ef5","metadata":{"id":"a7063ef5"},"outputs":[],"source":["# Age statistics\n","print(df['age'].describe())\n"]},{"cell_type":"code","execution_count":null,"id":"1b8d048c","metadata":{"id":"1b8d048c"},"outputs":[],"source":["# Gender and ethnicity counts\n","print(df['gender'].value_counts())\n","print(df['ethnicity'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"id":"cf94b2b1","metadata":{"id":"cf94b2b1"},"outputs":[],"source":["# Let's do some basic analysis of the age, ethnicity, and gender distributions\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Create age distribution plot\n","plt.figure(figsize=(10, 6))\n","sns.histplot(data=df, x='age', bins=30)\n","plt.title('Age Distribution')\n","plt.xlabel('Age')\n","plt.ylabel('Count')\n","plt.show()\n","\n","# Display summary statistics for age\n","print(\"\\\n","Age Statistics:\")\n","print(df['age'].describe())\n","\n","# Display value counts for ethnicity and gender\n","print(\"\\Ethnicity Distribution:\")\n","print(df['ethnicity'].value_counts())\n","\n","print(\"\\Gender Distribution:\")\n","print(df['gender'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"id":"9e35bb79","metadata":{"id":"9e35bb79"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Gender distribution plot\n","plt.figure(figsize=(8, 5))\n","\n","# Create a bar plot for gender distribution\n","gender_counts = df['gender'].value_counts()\n","bars = gender_counts.plot(kind='bar', edgecolor='black', width=0.10)  # Adjust width for thinner bars\n","\n","# Apply a colormap to the bars (similar shades as before)\n","for i, bar in enumerate(bars.patches):\n","    shade = i / len(bars.patches)  # Vary the shade from light to dark\n","    bar.set_facecolor(plt.cm.plasma(shade))  # Apply the plasma colormap with varying shades\n","\n","# Calculate the percentage of each gender\n","total_count = gender_counts.sum()\n","percentages = (gender_counts / total_count) * 100\n","\n","# Add the percentage text on top of the bars\n","for i, bar in enumerate(bars.patches):\n","    percentage = percentages[i]\n","    # Display the percentage value above the bar\n","    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n","             f'{percentage:.2f}%',\n","             ha='center', va='bottom', fontsize=12, color='black')\n","\n","plt.title('Gender Distribution', fontsize=14, color='darkblue')\n","plt.xlabel('Gender (0=Male, 1=Female)', fontsize=12, color='darkgreen')\n","plt.ylabel('Count', fontsize=12, color='darkgreen')\n","plt.grid(False)  # Remove grid for a cleaner look\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"30dee736","metadata":{"id":"30dee736"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Check if the 'pixels' column contains strings before applying the split\n","if isinstance(df['pixels'].iloc[0], str):\n","    df['pixels'] = df['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\"))\n","\n","# Convert any lists to NumPy arrays explicitly (if necessary)\n","df['pixels'] = df['pixels'].apply(np.array)\n","\n","# Plot a few sample images\n","fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n","for i, ax in enumerate(axes):\n","    # Ensure proper reshaping\n","    pixels = df['pixels'].iloc[i].reshape(48, 48)  # Reshape to 48x48\n","    ax.imshow(pixels, cmap='gray')\n","    ax.axis('off')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"9d3a65bf","metadata":{"id":"9d3a65bf"},"outputs":[],"source":["df['age'] = df['age'].fillna(df['age'].mean()) #Handle Missing Values\n","df['pixels'] = df['pixels'].apply(lambda x: np.array(x) / 255.0) #Normalize the pixel values\n","df['age'] = df['age'] / 100.0 #Normalize the age column\n"]},{"cell_type":"code","execution_count":null,"id":"659f0221","metadata":{"id":"659f0221"},"outputs":[],"source":["# Filter out rows with invalid pixel shapes\n","df = df[df['pixels'].apply(lambda x: x.shape == (48 * 48,))]\n","\n","# Verify again\n","shapes = df['pixels'].apply(lambda x: x.shape)\n","print(\"Remaining unique shapes in 'pixels':\", shapes.unique())\n"]},{"cell_type":"code","execution_count":null,"id":"d5ed35b7","metadata":{"id":"d5ed35b7"},"outputs":[],"source":["# Convert the 'pixels' column into a 3D NumPy array\n","X = np.stack(df['pixels'].values).reshape(-1, 48, 48)  # Reshape to (num_samples, 48, 48)\n","\n","# Extract the target variable\n","y = df['age'].values\n","\n","# Verify the shapes\n","print(f\"Features (X): {X.shape}, Target (y): {y.shape}\")\n"]},{"cell_type":"code","execution_count":null,"id":"3f5f2966","metadata":{"id":"3f5f2966"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split data into training (80%) and temporary (20%) sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Further split the temporary set into validation (10%) and test (10%) sets\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# Print the shapes to verify\n","print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n","print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n","print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"]},{"cell_type":"code","execution_count":null,"id":"e3d6b533","metadata":{"id":"e3d6b533"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Convert data to tensors and add channel dimension\n","train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32).unsqueeze(1),\n","                               torch.tensor(y_train, dtype=torch.float32))\n","val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32).unsqueeze(1),\n","                             torch.tensor(y_val, dtype=torch.float32))\n","test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32).unsqueeze(1),\n","                              torch.tensor(y_test, dtype=torch.float32))\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Verify DataLoader outputs\n","for inputs, targets in train_loader:\n","    print(f\"Inputs shape: {inputs.shape}, Targets shape: {targets.shape}\")\n","    break\n"]},{"cell_type":"code","execution_count":null,"id":"93d71363","metadata":{"id":"93d71363"},"outputs":[],"source":["from torchvision.models import resnet18, ResNet18_Weights\n","import torch.nn as nn\n","\n","# Load the pre-trained ResNet-18 model with updated weights parameter\n","model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","\n","# Modify the first convolutional layer to accept 1 channel (grayscale)\n","model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","\n","# Modify the final fully connected layer for regression (1 output for age)\n","model.fc = nn.Linear(model.fc.in_features, 1)\n","\n","# Move model to the appropriate device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"id":"e6ad442e","metadata":{"id":"e6ad442e"},"outputs":[],"source":["import torch.optim as optim\n","\n","# Define the loss function\n","criterion = nn.MSELoss()\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"]},{"cell_type":"code","execution_count":null,"id":"74c202ac","metadata":{"id":"74c202ac"},"outputs":[],"source":["num_epochs = 10  # You can adjust this depending on the dataset size and performance\n","\n","for epoch in range(num_epochs):\n","    model.train()  # Set model to training mode\n","    running_loss = 0.0\n","\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs.squeeze(), targets)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    # Calculate average training loss for the epoch\n","    train_loss = running_loss / len(train_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}\")\n","\n","    # Validation step\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for val_inputs, val_targets in val_loader:\n","            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n","            val_outputs = model(val_inputs)\n","            val_loss += criterion(val_outputs.squeeze(), val_targets).item()\n","\n","    # Calculate average validation loss\n","    val_loss /= len(val_loader)\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"ba46992a","metadata":{"id":"ba46992a"},"outputs":[],"source":["model.eval()\n","test_loss = 0.0\n","absolute_error = 0.0\n","\n","with torch.no_grad():\n","    for inputs, targets in test_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        test_loss += criterion(outputs.squeeze(), targets).item()\n","        absolute_error += torch.sum(torch.abs(outputs.squeeze() - targets)).item()\n","\n","# Calculate average test loss and Mean Absolute Error (MAE)\n","test_loss /= len(test_loader)\n","mae = absolute_error / len(test_dataset)\n","\n","print(f\"Test Loss (MSE): {test_loss:.4f}\")\n","print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"81824a3b","metadata":{"id":"81824a3b"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Fetch a batch of data from the test loader\n","inputs, targets = next(iter(test_loader))\n","inputs, targets = inputs.to(device), targets.to(device)\n","\n","# Get model predictions\n","model.eval()\n","with torch.no_grad():\n","    predictions = model(inputs)\n","\n","# Convert normalized predictions and targets back to the original scale\n","predictions = predictions.squeeze().cpu().numpy() * 100  # Scale back\n","targets = targets.cpu().numpy() * 100  # Scale back\n","\n","# Plot the results\n","plt.figure(figsize=(10, 6))\n","plt.plot(targets, label=\"Actual Values\", marker='o', linestyle='--')\n","plt.plot(predictions, label=\"Predicted Values\", marker='o', linestyle='-')\n","plt.xlabel(\"Sample Index\")\n","plt.ylabel(\"Age\")\n","plt.title(\"Actual vs Predicted Ages (Original Scale)\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"41d4b7c2","metadata":{"id":"41d4b7c2"},"outputs":[],"source":["# Define the learning rate scheduler\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n","\n","# Training loop with learning rate logging\n","num_epochs = 10\n","best_val_loss = float('inf')\n","\n","for epoch in range(num_epochs):\n","    # Training step\n","    model.train()\n","    train_loss = 0.0\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs.squeeze(), targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    train_loss /= len(train_loader)\n","\n","    # Validation step\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            val_loss += criterion(outputs.squeeze(), targets).item()\n","\n","    val_loss /= len(val_loader)\n","\n","    # Update the learning rate based on validation loss\n","    scheduler.step(val_loss)\n","\n","    # Get current learning rate\n","    current_lr = scheduler.optimizer.param_groups[0]['lr']\n","\n","    # Save the best model\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_tuned_model_with_scheduler.pth')\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Learning Rate: {current_lr:.6f}\")\n","\n","print(\"Training complete. Best Validation Loss: {:.4f}\".format(best_val_loss))\n"]},{"cell_type":"code","execution_count":null,"id":"67153fb5","metadata":{"id":"67153fb5"},"outputs":[],"source":["# Load the model weights only\n","model.load_state_dict(torch.load('best_tuned_model_with_scheduler.pth', weights_only=True))\n","model.eval()\n","\n","test_loss = 0.0\n","absolute_error = 0.0\n","\n","with torch.no_grad():\n","    for inputs, targets in test_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        test_loss += criterion(outputs.squeeze(), targets).item()\n","        absolute_error += torch.sum(torch.abs(outputs.squeeze() - targets)).item()\n","\n","# Calculate average test loss and Mean Absolute Error (MAE)\n","test_loss /= len(test_loader)\n","mae = absolute_error / len(test_dataset)\n","\n","print(f\"Test Loss (MSE): {test_loss:.4f}\")\n","print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"0ce45a8b","metadata":{"id":"0ce45a8b"},"outputs":[],"source":["!pip install optuna optuna-integration[pytorch_lightning]\n"]},{"cell_type":"code","execution_count":null,"id":"e5f240e6","metadata":{"id":"e5f240e6"},"outputs":[],"source":["import optuna\n","from optuna.integration import PyTorchLightningPruningCallback\n","\n","def objective(trial):\n","    # Define the hyperparameter space\n","    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n","    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n","    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])\n","\n","    # Set up DataLoaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    # Load and configure the model\n","    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","    model.fc = nn.Linear(model.fc.in_features, 1)\n","    model = model.to(device)\n","\n","    # Define optimizer\n","    if optimizer_name == 'adam':\n","        optimizer = optim.Adam(model.parameters(), lr=lr)\n","    elif optimizer_name == 'sgd':\n","        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n","    elif optimizer_name == 'rmsprop':\n","        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n","\n","    # Define loss function\n","    criterion = nn.MSELoss()\n","\n","    # Train and evaluate\n","    val_loss = train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)\n","    return val_loss\n","\n","# Run Bayesian Optimization\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=20)\n","\n","# Best hyperparameters\n","print(\"Best hyperparameters:\", study.best_params)\n","print(\"Best validation loss:\", study.best_value)\n"]},{"cell_type":"code","execution_count":null,"id":"ba8186fc","metadata":{"id":"ba8186fc"},"outputs":[],"source":["# Set up DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64)\n","\n","# Load and configure the model\n","model = resnet18(weights=ResNet18_Weights.DEFAULT)\n","model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","model.fc = nn.Linear(model.fc.in_features, 1)\n","model = model.to(device)\n","\n","# Define optimizer and loss\n","optimizer = optim.Adam(model.parameters(), lr=0.00042021477048710334)\n","criterion = nn.MSELoss()\n","\n","# Train with the best hyperparameters\n","num_epochs = 10  # Adjust based on computational resources\n","train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs)\n"]},{"cell_type":"code","execution_count":null,"id":"535116bd","metadata":{"id":"535116bd"},"outputs":[],"source":["# Test evaluation\n","test_loss = 0.0\n","absolute_error = 0.0\n","\n","model.eval()\n","with torch.no_grad():\n","    for inputs, targets in test_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        test_loss += criterion(outputs.squeeze(), targets).item()\n","        absolute_error += torch.sum(torch.abs(outputs.squeeze() - targets)).item()\n","\n","# Calculate average test loss and Mean Absolute Error (MAE)\n","test_loss /= len(test_loader)\n","mae = absolute_error / len(test_dataset)\n","\n","print(f\"Test Loss (MSE): {test_loss:.4f}\")\n","print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"fe1f392d","metadata":{"id":"fe1f392d"},"outputs":[],"source":["# Generate a html file\n","!jupyter nbconvert --to html \"/content/drive/MyDrive/IS675_data/DL Project/Final_DL.ipynb\"\n"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}